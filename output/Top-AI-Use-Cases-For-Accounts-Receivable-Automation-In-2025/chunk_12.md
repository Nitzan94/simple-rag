<div dir="rtl">

# Chunk 12/20

xplain their decisions; for AR software, this
means ensuring that the algorithms are transparent and users can understand how
it makes decisions. Billtrust’s explainable AI uses SHAP value charts to ensure
transparent and defensible credit decisions, aiding regulatory compliance.
BlackLine provides visualizations, dashboards, and interfaces to help users
understand AI outputs, using interpretable models and explainable AI techniques
for transparency.
• Liability. Companies using AI-based AR software must understand that if the AI
makes an error in applying an incoming payment to an open invoice, the firm using
the software is fully liable. So firms must establish their own AI governance
guardrails, such as setting appropriate tolerance levels for AI-generated decisions.
Esker maintains human oversight in AI-driven processes to ensure that critical
decisions do not rely solely on algorithms.
• User adoption and awareness. Employees’ resistance to change and lack of
understanding of AI c

</div>